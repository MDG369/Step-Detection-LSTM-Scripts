{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval() \n",
    "torch.save(model.state_dict(), '')\n",
    "print('Model weights saved to step_lstm_more_stairsup.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(6, 64, 2, 0.2)\n",
    "model.load_state_dict(torch.load(''))\n",
    "model.eval()\n",
    "print('Model weights loaded from model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class StepDataset(Dataset):\n",
    "    def __init__(self, folder_path, window_size):\n",
    "        self.window_size = window_size\n",
    "        self.data = self.load_data(folder_path)\n",
    "        self.features = self.data[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']].values\n",
    "        self.labels = self.data['step_timestamp'].apply(lambda x: 1 if x in [1, 2, 3] else 0).values  # Convert 1, 2, 3 to 1\n",
    "\n",
    "    def load_data(self, folder_path):\n",
    "        # Recursively load all .csv files from the folder and its subfolders\n",
    "        all_files = glob.glob(os.path.join(folder_path, '**', '*.csv'), recursive=True)\n",
    "        df_list = [pd.read_csv(file) for file in all_files]\n",
    "        return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_size + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx:idx + self.window_size]\n",
    "        y = self.labels[idx + self.window_size - 1]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "folder_path = r''\n",
    "window_size = 160\n",
    "batch_size = 32\n",
    "test_split_ratio = 0.15 \n",
    "\n",
    "# Create dataset\n",
    "dataset = StepDataset(folder_path, window_size)\n",
    "\n",
    "# Calculate the number of samples for training and testing\n",
    "test_size = int(len(dataset) * test_split_ratio)\n",
    "train_size = len(dataset) - test_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]  \n",
    "        out = self.fc(out)  \n",
    "        return out\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model\n",
    "model = LSTM(6, 64, 2, 0.2).to(device)\n",
    "\n",
    "num_steps = sum(dataset.labels) \n",
    "num_no_steps = len(dataset.labels) - num_steps \n",
    "pos_weight = torch.tensor([num_no_steps / num_steps], dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Evaluate the model with leeway\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "sampling_rate = 100 \n",
    "time_leeway_ms = 100 \n",
    "sample_leeway = int((time_leeway_ms / 1000) * sampling_rate)\n",
    "\n",
    "real_steps = 0\n",
    "counted_steps = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs).squeeze()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "\n",
    "        labels_np = labels.cpu().numpy()\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "\n",
    "        for i in range(len(labels_np)):\n",
    "            label = labels_np[i]\n",
    "            pred = predicted_np[i]\n",
    "\n",
    "            if label != 0:\n",
    "                real_steps += 1\n",
    "            if label != 0 and torch.any(predicted == label):\n",
    "                counted_steps += 1\n",
    "            if torch.any(predicted == label):\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "try:\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy with leeway: {accuracy:.2f}%')\n",
    "    print(f'Real steps: {real_steps}, Counted steps: {counted_steps}')\n",
    "except ZeroDivisionError:\n",
    "    print('No steps detected in the test set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST A FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time  # Import the time module\n",
    "\n",
    "def test_single_file(model, csv_file, window_size, sample_leeway, output_file, device='cpu'):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(csv_file)\n",
    "    features = data[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']].values\n",
    "    timestamps = data['step_timestamp'].values\n",
    "\n",
    "    inputs = []\n",
    "    for i in range(len(features) - window_size + 1):\n",
    "        x = features[i:i + window_size]\n",
    "        inputs.append(torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_steps = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(inputs)):\n",
    "            input_tensor = inputs[i].unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "            \n",
    "            output = model(input_tensor).squeeze()\n",
    "            \n",
    "            predicted = (output > 0.5).float()  # Use threshold to determine class (0 or 1)\n",
    "\n",
    "            label = timestamps[i + window_size - 1]\n",
    "            print(f'Predicted: {predicted}, Label: {label}')\n",
    "            # Check if the prediction is within the leeway\n",
    "            if abs(predicted.item() - label) <= sample_leeway:\n",
    "                correct += 1\n",
    "            predicted_steps.append(predicted.item())\n",
    "            total += 1\n",
    "\n",
    "    if total != 0:\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Accuracy with leeway: {accuracy}%')\n",
    "\n",
    "    predicted_steps_df = pd.DataFrame(predicted_steps, columns=['predicted_step_timestamp'])\n",
    "    predicted_steps_df.to_csv(output_file, index=False)\n",
    "    print(f'Predicted steps saved to {output_file}')\n",
    "\n",
    "def process_folder(model, input_folder, output_folder, window_size, sample_leeway, device='cpu'):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate over all files and subfolders in the input folder\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.csv'):\n",
    "                input_file = os.path.join(root, filename)\n",
    "                relative_path = os.path.relpath(input_file, input_folder)\n",
    "                output_file = os.path.join(output_folder, relative_path)\n",
    "                os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "                print(f'Processing {input_file}...')\n",
    "                test_single_file(model, input_file, window_size, sample_leeway, output_file, device)\n",
    "\n",
    "# Parameters\n",
    "input_folder = r''\n",
    "output_folder = r''\n",
    "window_size = 160\n",
    "sampling_rate = 100 \n",
    "time_leeway_ms = 100 \n",
    "sample_leeway = int((time_leeway_ms / 1000) * sampling_rate) \n",
    "\n",
    "# Initialize the model (make sure to load the trained model weights)\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]  # Take the output of the last timestep\n",
    "        out = self.fc(out)  # Logits\n",
    "        return out\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTM(6, 64, 2, 0.2).to(device)\n",
    "model.load_state_dict(torch.load(''))  \n",
    "\n",
    "# Process the folder\n",
    "process_folder(model, input_folder, output_folder, window_size, sample_leeway, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST A SINGLE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = r''\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Drop the first column (by index)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "# Save the modified DataFrame to a new file\n",
    "output_file = 'combined_eti10krokow4634c53c-0399-41a5-baa0-73475c39fc68_accelerometer.cs'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"First column removed. Saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
